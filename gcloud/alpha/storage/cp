NAME
    gcloud alpha storage cp - upload, download, and copy Cloud Storage objects

SYNOPSIS
    gcloud alpha storage cp [SOURCE ...] DESTINATION [--all-versions, -A]
        [--cache-control=CACHE_CONTROL] [--no-clobber, -n]
        [--content-disposition=CONTENT_DISPOSITION]
        [--content-encoding=CONTENT_ENCODING]
        [--content-language=CONTENT_LANGUAGE] [--content-md5=MD5_DIGEST]
        [--content-type=CONTENT_TYPE] [--continue-on-error, -c]
        [--custom-metadata=[CUSTOM_METADATA,...]] [--custom-time=CUSTOM_TIME]
        [--do-not-decompress] [--if-generation-match=GENERATION]
        [--if-metageneration-match=METAGENERATION] [--ignore-symlinks]
        [--manifest-path=MANIFEST_PATH, -L MANIFEST_PATH]
        [--preserve-posix, -P] [--print-created-message, -v]
        [--read-paths-from-stdin, -I] [--recursive, -R, -r]
        [--skip-unsupported, -U]
        [--storage-class=STORAGE_CLASS, -s STORAGE_CLASS]
        [--canned-acl=PREDEFINED_ACL,
          --predefined-acl=PREDEFINED_ACL, -a PREDEFINED_ACL
          | --preserve-acl, -p]
        [--gzip-in-flight=[FILE_EXTENSIONS,...], -j [FILE_EXTENSIONS,...]
          | --gzip-in-flight-all, -J
          | --gzip-local=[FILE_EXTENSIONS,...], -z [FILE_EXTENSIONS,...]
          | --gzip-local-all, -Z] [GCLOUD_WIDE_FLAG ...]

DESCRIPTION
    (ALPHA) Copy data between your local file system and the cloud, within the
    cloud, and between cloud storage providers.

EXAMPLES
    The following command uploads all text files from the local directory to a
    bucket:

        $ gcloud alpha storage cp *.txt gs://my-bucket

    The following command downloads all text files from a bucket to your
    current directory:

        $ gcloud alpha storage cp gs://my-bucket/*.txt .

    The following command transfers all text files from a bucket to a different
    cloud storage provider:

        $ gcloud alpha storage cp gs://my-bucket/*.txt s3://my-bucket

    Use the --recursive option to copy an entire directory tree. The following
    command uploads the directory tree dir:

        $ gcloud alpha storage cp --recursive dir gs://my-bucket

POSITIONAL ARGUMENTS
     [SOURCE ...]
        The source path(s) to copy.

     DESTINATION
        The destination path.

FLAGS
     --all-versions, -A
        Copy all source versions from a source bucket or folder. If not set,
        only the live version of each source object is copied.

        Note: This option is only useful when the destination bucket has Object
        Versioning enabled. Additionally, the generation numbers of copied
        versions do not necessarily match the order of the original generation
        numbers.

     --cache-control=CACHE_CONTROL
        How caches should handle requests and responses.

     --no-clobber, -n
        Do not overwrite existing files or objects at the destination. Skipped
        items will be printed. This option performs an additional GET request
        for cloud objects before attempting an upload.

     --content-disposition=CONTENT_DISPOSITION
        How content should be displayed.

     --content-encoding=CONTENT_ENCODING
        How content is encoded (e.g. gzip).

     --content-language=CONTENT_LANGUAGE
        Content's language (e.g. en signifies "English").

     --content-md5=MD5_DIGEST
        Manually specified MD5 hash digest for the contents of an uploaded
        file. This flag cannot be used when uploading multiple files. The
        custom digest is used by the cloud provider for validation.

     --content-type=CONTENT_TYPE
        Type of data contained in the object (e.g. text/html).

     --continue-on-error, -c
        If any operations are unsuccessful, the command will exit with a
        non-zero exit status after completing the remaining operations. This
        flag takes effect only in sequential execution mode (i.e. processor and
        thread count are set to 1). Parallelism is default.

     --custom-metadata=[CUSTOM_METADATA,...]
        Custom metadata fields set by user.

     --custom-time=CUSTOM_TIME
        Custom time for Google Cloud Storage objects in RFC 3339 format.

     --do-not-decompress
        Do not automatically decompress downloaded gzip files.

     --if-generation-match=GENERATION
        Execute only if the generation matches the generation of the requested
        object.

     --if-metageneration-match=METAGENERATION
        Execute only if the metageneration matches the metageneration of the
        requested object.

     --ignore-symlinks
        Ignore file symlinks instead of copying what they point to. Symlinks
        pointing to directories will always be ignored.

     --manifest-path=MANIFEST_PATH, -L MANIFEST_PATH
        Outputs a manifest log file with detailed information about each item
        that was copied. This manifest contains the following information for
        each item:

        ◆ Source path.
        ◆ Destination path.
        ◆ Source size.
        ◆ Bytes transferred.
        ◆ MD5 hash.
        ◆ Transfer start time and date in UTC and ISO 8601 format.
        ◆ Transfer completion time and date in UTC and ISO 8601 format.
        ◆ Final result of the attempted transfer: OK, error, or skipped.
        ◆ Details, if any.

        If the manifest file already exists, gcloud storage appends log items
        to the existing file.

        Objects that are marked as "OK" or "skipped" in the existing manifest
        file are not retried by future commands. Objects marked as "error" are
        retried.

     --preserve-posix, -P
        Causes POSIX attributes to be preserved when objects are copied. With
        this feature enabled, gcloud storage will copy several fields provided
        by the stat command: access time, modification time, owner UID, owner
        group GID, and the mode (permissions) of the file.

        For uploads, these attributes are read off of local files and stored in
        the cloud as custom metadata. For downloads, custom cloud metadata is
        set as POSIX attributes on files after they are downloaded.

        On Windows, this flag will only set and restore access time and
        modification time because Windows doesn't have a notion of POSIX UID,
        GID, and mode.

     --print-created-message, -v
        Prints the version-specific URL for each copied object.

     --read-paths-from-stdin, -I
        Read the list of resources to copy from stdin. No need to enter a
        source argument if this flag is present. Example: "storage cp -I
        gs://bucket/destination" Note: To copy the contents of one file
        directly from stdin, use "-" as the source argument without the "-I"
        flag.

     --recursive, -R, -r
        Recursively copy the contents of any directories that match the source
        path expression.

     --skip-unsupported, -U
        Skip objects with unsupported object types.Currently, the only
        unsupported category is Amazon S3 objects with the GLACIER storage
        class.

     --storage-class=STORAGE_CLASS, -s STORAGE_CLASS
        Specify the storage class of the destination object. If not specified,
        the default storage class of the destination bucket is used. This
        option is not valid for copying to non-cloud destinations.

     At most one of these can be specified:

       --canned-acl=PREDEFINED_ACL, --predefined-acl=PREDEFINED_ACL, -a PREDEFINED_ACL
          Applies predefined, or "canned," ACLs to a copied object. See docs
          for a list of predefined ACL constants:
          https://cloud.google.com/storage/docs/access-control/lists#predefined-acl

       --preserve-acl, -p
          Preserves ACLs when copying in the cloud. This option is Google Cloud
          Storage-only, and you need OWNER access to all copied objects. If all
          objects in the destination bucket should have the same ACL, you can
          also set a default object ACL on that bucket instead of using this
          flag.

     At most one of these can be specified:

       --gzip-in-flight=[FILE_EXTENSIONS,...], -j [FILE_EXTENSIONS,...]
          Applies gzip transport encoding to any file upload whose extension
          matches the input extension list. This is useful when uploading files
          with compressible content such as .js, .css, or .html files. This
          also saves network bandwidth while leaving the data uncompressed in
          Cloud Storage.

          When you specify the --gzip-in-flight option, files being uploaded
          are compressed in-memory and on-the-wire only. Both the local files
          and Cloud Storage objects remain uncompressed. The uploaded objects
          retain the Content-Type and name of the original files.

       --gzip-in-flight-all, -J
          Applies gzip transport encoding to file uploads. This option works
          like the --gzip-in-flight option described above, but it applies to
          all uploaded files, regardless of extension.

          CAUTION: If some of the source files don't compress well, such as
          binary data, using this option may result in longer uploads.

       --gzip-local=[FILE_EXTENSIONS,...], -z [FILE_EXTENSIONS,...]
          Applies gzip content encoding to any file upload whose extension
          matches the input extension list. This is useful when uploading files
          with compressible content such as .js, .css, or .html files. This
          saves network bandwidth and space in Cloud Storage.

          When you specify the --gzip-local option, the data from files is
          compressed before it is uploaded, but the original files are left
          uncompressed on the local disk. The uploaded objects retain the
          Content-Type and name of the original files. However, the
          Content-Encoding metadata is set to gzip and the Cache-Control
          metadata set to no-transform. The data remains compressed on Cloud
          Storage servers and will not be decompressed on download by gcloud
          stroage because of the no-transform field.

          Since the local gzip option compresses data prior to upload, it is
          not subject to the same compression buffer bottleneck of the
          in-flight gzip option.

       --gzip-local-all, -Z
          Applies gzip content encoding to file uploads. This option works like
          the --gzip-local option described above, but it applies to all
          uploaded files, regardless of extension.

          CAUTION: If some of the source files don't compress well, such as
          binary data, using this option may result in files taking up more
          space in the cloud than they would if left uncompressed.

GCLOUD WIDE FLAGS
    These flags are available to all commands: --access-token-file, --account,
    --billing-project, --configuration, --flags-file, --flatten, --format,
    --help, --impersonate-service-account, --log-http, --project, --quiet,
    --trace-token, --user-output-enabled, --verbosity.

    Run $ gcloud help for details.

NOTES
    This command is currently in alpha and might change without notice. If this
    command fails with API permission errors despite specifying the correct
    project, you might be trying to access an API with an invitation-only early
    access allowlist.

