NAME
    gcloud alpha storage batch-operations jobs create - create a new batch
        operation job

SYNOPSIS
    gcloud alpha storage batch-operations jobs create BATCH_JOB
        (--bucket=BUCKET | --bucket-list=[BUCKETS,...])
        (--included-object-prefixes=[PREFIXES,...]
          | --manifest-location=MANIFEST_LOCATION)
        (--put-metadata=KEY=VALUE,[KEY=VALUE,...]
          | --rewrite-object=KEY=VALUE,[KEY=VALUE,...]
          | [--delete-object : --enable-permanent-object-deletion]
          | --[no-]put-object-event-based-hold
          --[no-]put-object-temporary-hold) [--description=DESCRIPTION]
        [--dry-run]
        [--log-actions=[LOG_ACTIONS,...]
          --log-action-states=[LOG_ACTION_STATES,...]] [GCLOUD_WIDE_FLAG ...]

DESCRIPTION
    (ALPHA) Create a batch operation job, allowing you to perform operations
    such as deletion, updating metadata, and more on objects in a serverless
    manner.

EXAMPLES
    The following example command creates a batch job, named my-dry-run, that
    performs a dry run of object deletion on bucket my-bucket for objects
    specified in the manifest file gs://my-bucket/manifest.csv:

        $ gcloud alpha storage batch-operations jobs create my-dry-run-job \
          --bucket=my-bucket \
          --manifest-location=gs://my-bucket/manifest.csv \
          --delete-object --dry-run

    The following example command creates a batch job, named my-job, that
    performs object deletion on bucket my-bucket for objects specified in the
    manifest file gs://my-bucket/manifest.csv:

        $ gcloud alpha storage batch-operations jobs create my-job \
          --bucket=my-bucket \
          --manifest-location=gs://my-bucket/manifest.csv --delete-object

    The following example command creates a batch job, named my-job, that
    performs object deletion on buckets my-bucket-1 and my-bucket-2 for all
    objects in them:

        $ gcloud alpha storage batch-operations jobs create my-job \
          --bucket-list=my-bucket-1,my-bucket-2 \
          --included-object-prefixes='' --delete-object

    The following example command creates a batch job, named my-job, that
    updates object metadata Content-Disposition to inline, Content-Language to
    en, and sets object retention mode to locked on bucket my-bucket for
    objects with prefixes prefix1 or prefix2:

        $ gcloud alpha storage batch-operations jobs create my-job \
          --bucket=my-bucket --included-object-prefixes=prefix1,prefix2 \
          --put-metadata=Content-Disposition=inline,Content-Language=en,\
        Retain-Until=2025-01-01T00:00:00Z,Retention-Mode=locked

    The following example command creates a batch job, named my-job, that puts
    object event based hold on objects in bucket my-bucket with logging config
    enabled for corresponding transform action and succeeded and failed action
    states:

        $ gcloud alpha storage batch-operations jobs create my-job \
          --bucket=my-bucket --put-object-event-based-hold \
          --put-metadata=Content-Disposition=inline,Content-Language=en \
          --log-actions=transform --log-action-states=succeeded,failed

POSITIONAL ARGUMENTS
     Batch job resource - The batch job to create. This represents a Cloud
     resource. (NOTE) Some attributes are not given arguments in this group but
     can be set in other ways.

     To set the project attribute:
      ◆ provide the argument batch_job on the command line with a fully
        specified name;
      ◆ provide the argument --project on the command line;
      ◆ set the property core/project.

     To set the location attribute:
      ◆ provide the argument batch_job on the command line with a fully
        specified name;
      ◆ The default is global.

     This must be specified.

       BATCH_JOB
          ID of the batch-job or fully qualified identifier for the batch-job.

          To set the batch-job attribute:
          ▸ provide the argument batch_job on the command line.

REQUIRED FLAGS
     Exactly one of these must be specified:

       --bucket=BUCKET
          Bucket containing the objects that the batch job will operate on.

       --bucket-list=[BUCKETS,...]
          List of buckets containing the objects that the batch job will
          operate on.

     Source specifying objects to perform batch operations on. Must be one of
     --manifest-location=``MANIFEST_LOCATION or
     --included-object-prefixes=``COMMA_SEPARATED_PREFIXES

     Exactly one of these must be specified:

       --included-object-prefixes=[PREFIXES,...]
          A comma-separated list of object prefixes to describe the objects
          being transformed. An empty string means all objects in the bucket.

       --manifest-location=MANIFEST_LOCATION
          An absolute path to the manifest source file in a Google Cloud
          Storage bucket. The file must be a CSV file where each row specifies
          the object details i.e. ProjectId, BucketId, and Name. Generation may
          optionally be specified. When generation is not specified, the live
          object is acted upon. Format:
          --manifest-location=gs://bucket_name/path/manifest_name.csv

     Transformation to be performed on the objects.

     Exactly one of these must be specified:

       --put-metadata=KEY=VALUE,[KEY=VALUE,...]
          Sets object metadata. To set how content should be displayed, specify
          the the key-value pair Content-Disposition={VALUE}. To set how
          content is encoded (e.g. "gzip"), specify the key-value pair
          Content-Encoding={VALUE}. To set content's language (e.g. "en"
          signifies "English"), specify the key-value pair
          Content-Language={VALUE}. To set the type of data contained in the
          object (e.g. "text/html"), specify the key-value pair
          Content-Type={VALUE}. To set how caches should handle requests and
          responses, specify the key-value pair Cache-Control={VALUE}. To set
          custom time for Cloud Storage objects in RFC 3339 format, specify the
          key-value pair Custom-Time={VALUE}. To set object retention, specify
          Retain-Until={TIMESTAMP} in RFC 3339 format and Retention-Mode={MODE}
          where mode can be Locked or Unlocked. To set custom metadata on
          objects, specify key-value pairs {CUSTOM-KEY}:{VALUE}. Note that all
          predefined keys (e.g. Content-Disposition) are case-insensitive. Any
          other key that is not specified above will be treated as a custom
          key. To clear a field, provide the key with an empty value (e.g.
          Content-Disposition=). Multiple key-value pairs can be specified by
          separating them with commas. For example,
          --put-metadata=Content-Disposition=inline,Content-Encoding=gzip

       --rewrite-object=KEY=VALUE,[KEY=VALUE,...]
          Rewrites object and the specified metadata. Currently only supports
          rewriting kms-key. A metadata field MUST be specified. For example,
          --rewrite-object=kms-key=projects/PROJECT_ID/locations/LOCATION/keyRings/KEY_RING/cryptoKeys/CRYPTO_KEY
          will rewrite the Cloud KMS key that will be used to encrypt the
          object.

       Describes options to delete objects.

         --delete-object
            If this flag is set, objects specified in source will be deleted.
            When versioning is enabled on the buckets, live objects in
            versioned buckets will become noncurrent and objects that were
            already noncurrent will be skipped.

            This flag argument must be specified if any of the other arguments
            in this group are specified.

         --enable-permanent-object-deletion
            If this flag is set and versioning is enabled on the buckets, both
            live and noncurrent objects will be permanently deleted.

       Describes options to update object hold.

         --[no-]put-object-event-based-hold
            Sets or unsets object event based holds state. When object event
            based hold is set, object cannot be deleted or replaced. Use
            --put-object-event-based-hold to enable and
            --no-put-object-event-based-hold to disable.

         --[no-]put-object-temporary-hold
            Sets or unsets object temporary holds state. When object temporary
            hold is set, object cannot be deleted or replaced. Use
            --put-object-temporary-hold to enable and
            --no-put-object-temporary-hold to disable.

FLAGS
     --description=DESCRIPTION
        Description for the batch job.

     --dry-run
        If true, the job will run in dry run mode, returning the total object
        count and, if the object configuration is a prefix list, the bytes
        found from source. No transformations will be performed.

LOGGING_CONFIG FLAGS
     LOGGING CONFIG

     Configure which transfer actions and action states are reported when logs
     are generated for this job. Logs can be viewed by running the following
     command: gcloud logging read
     "resource.type=storagebatchoperations.googleapis.com/Job"

       --log-actions=[LOG_ACTIONS,...]
          Define the batch job actions to report in logs. (e.g.,
          --log-actions=transform). LOG_ACTIONS must be (only one value is
          supported): transform.

       --log-action-states=[LOG_ACTION_STATES,...]
          The states in which the actions specified in --log-actions are
          logged. Separate multiple states with a comma, omitting the space
          after the comma (e.g., --log-action-states=succeeded,failed).
          LOG_ACTION_STATES must be one of: failed, succeeded.

GCLOUD WIDE FLAGS
    These flags are available to all commands: --access-token-file, --account,
    --billing-project, --configuration, --flags-file, --flatten, --format,
    --help, --impersonate-service-account, --log-http, --project, --quiet,
    --trace-token, --user-output-enabled, --verbosity.

    Run $ gcloud help for details.

NOTES
    This command is currently in alpha and might change without notice. If this
    command fails with API permission errors despite specifying the correct
    project, you might be trying to access an API with an invitation-only early
    access allowlist. This variant is also available:

        $ gcloud storage batch-operations jobs create

