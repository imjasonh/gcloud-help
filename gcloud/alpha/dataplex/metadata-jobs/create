NAME
    gcloud alpha dataplex metadata-jobs create - create a Dataplex Metadata Job

SYNOPSIS
    gcloud alpha dataplex metadata-jobs create
        [[METADATA_JOB] --location=LOCATION] --type=TYPE
        (--export-output-path=EXPORT_OUTPUT_PATH
          ((--export-entry-groups=[EXPORT_ENTRY_GROUPS,...]
          | --export-organization-level=EXPORT_ORGANIZATION_LEVEL
          | --export-projects=[EXPORT_PROJECTS,...])
          : --export-aspect-types=[EXPORT_ASPECT_TYPES,...]
          --export-entry-types=[EXPORT_ENTRY_TYPES,...])
          | [--import-aspect-sync-mode=IMPORT_ASPECT_SYNC_MODE
          --import-entry-sync-mode=IMPORT_ENTRY_SYNC_MODE
          --import-source-storage-uri=IMPORT_SOURCE_STORAGE_URI
          (--import-aspect-types=[IMPORT_ASPECT_TYPES,...]
          --import-entry-groups=[IMPORT_ENTRY_GROUPS,...]
          --import-entry-link-types=[IMPORT_ENTRY_LINK_TYPES,...]
          --import-entry-types=[IMPORT_ENTRY_TYPES,...]
          --import-glossaries=[IMPORT_GLOSSARIES,...]
          --import-referenced-entry-scopes=[IMPORT_REFERENCED_ENTRY_SCOPES,
          ...]) : --import-log-level=IMPORT_LOG_LEVEL
          --import-source-create-time=IMPORT_SOURCE_CREATE_TIME]) [--async]
        [--labels=[KEY=VALUE,...]] [--validate-only] [GCLOUD_WIDE_FLAG ...]

DESCRIPTION
    (ALPHA) A metadata job represents a long running job on Dataplex Catalog
    metadata entries. Some operations include importing and exporting metadata
    into entry groups through the usage of entry types and aspect types.

    The Metadata Job ID will be used to identify each configuration run. The
    Metadata Job id must follow these rules:
      ▪ Must contain only lowercase letters, numbers, and hyphens.
      ▪ Must start with a letter.
      ▪ Must end with a number or a letter.
      ▪ Must be between 1-63 characters.
      ▪ Must be unique within the customer project / location.

EXAMPLES
    To create a Dataplex Metadata Job with type IMPORT and name my-metadata-job
    in location us-central1 with additional parameters, run:

        $ gcloud alpha dataplex metadata-jobs create my-metadata-job \
            --location=us-central --project=test-project --type=import \
            --import-source-storage-uri=gs://test-storage/ \
            --import-source-create-time="2019-01-23T12:34:56.123456789Z" \
            --import-entry-sync-mode=FULL \
            --import-aspect-sync-mode=INCREMENTAL \
            --import-log-level="debug" \
            --import-entry-groups=projects/test-project/locations/\
        us-central1/entryGroups/eg1 \
            --import-entry-types="projects/test-project/locations/us-central\
        1/entryTypes/et1", \
            "projects/test-project/locations/us-central1/entryTypes/et2" \
            --import-aspect-types="projects/test-project/locations/us-centra\
        l1/aspectTypes/at1", \
            "projects/test-project/locations/us-central1/aspectTypes/at2"

    To create a Dataplex Metadata Job with type EXPORT and name my-metadata-job
    in location us-central1 with additional parameters, run:

        $ gcloud alpha dataplex metadata-jobs create my-metadata-job \
            --location=us-central --project=test-project --type=export \
            --export-output-path=gs://test-storage/ \
            --export-entry-groups=projects/test-project/locations/\
        us-central1/entryGroups/eg1 \
            --export-entry-types="projects/test-project/locations/us-central\
        1/entryTypes/et1", \
            "projects/test-project/locations/us-central1/entryTypes/et2" \
            --export-aspect-types="projects/test-project/locations/us-centra\
        l1/aspectTypes/at1", \
            "projects/test-project/locations/us-central1/aspectTypes/at2"

POSITIONAL ARGUMENTS
     Metadata job resource - Arguments and flags that define the Dataplex
     metdata job you want to create. The arguments in this group can be used to
     specify the attributes of this resource. (NOTE) Some attributes are not
     given arguments in this group but can be set in other ways.

     To set the project attribute:
      ◆ provide the argument metadata_job on the command line with a fully
        specified name;
      ◆ job ID is optional and will be generated if not specified with a
        fully specified name;
      ◆ provide the argument --project on the command line;
      ◆ set the property core/project.

     [METADATA_JOB]
        ID of the metadata job or fully qualified identifier for the metadata
        job.

        To set the metadata_job attribute:
        ◆ provide the argument metadata_job on the command line;
        ◆ job ID is optional and will be generated if not specified.

     --location=LOCATION
        The location of the Dataplex resource.

        To set the location attribute:
        ◆ provide the argument metadata_job on the command line with a fully
          specified name;
        ◆ job ID is optional and will be generated if not specified with a
          fully specified name;
        ◆ provide the argument --location on the command line;
        ◆ set the property dataplex/location.

REQUIRED FLAGS
     --type=TYPE
        Type. TYPE must be one of:

         EXPORT
            A Metadata Export Job will export entries and aspects from the
            declared Dataplex scope to the specified Cloud Storage location.
         IMPORT
            A Metadata Import Job will ingest, update, or delete entries and
            aspects into the declared Dataplex entry group.

     Settings for metadata job operation.

     Exactly one of these must be specified:

       Settings for metadata export job operation.

       --export-output-path=EXPORT_OUTPUT_PATH
          The Cloud Storage location to export metadata to.

          This flag argument must be specified if any of the other arguments in
          this group are specified.

       A boundary on the scope of impact that the metadata export job can have.

       At least one of these must be specified:

         --export-aspect-types=[EXPORT_ASPECT_TYPES,...]
            The list of aspect types to export metadata from.

         --export-entry-types=[EXPORT_ENTRY_TYPES,...]
            The list of entry types to export metadata from.

         The scope of resources to export metadata from.

         Exactly one of these must be specified:

           --export-entry-groups=[EXPORT_ENTRY_GROUPS,...]
              The list of entry groups to export metadata from.

           --export-organization-level=EXPORT_ORGANIZATION_LEVEL
              Whether to export metadata at the organization level.

           --export-projects=[EXPORT_PROJECTS,...]
              The list of projects to export metadata from.

       Settings for metadata import job operation.

       --import-aspect-sync-mode=IMPORT_ASPECT_SYNC_MODE
          Type. IMPORT_ASPECT_SYNC_MODE must be one of:

           FULL
              All resources in the job's scope are modified. If a resource
              exists in Dataplex but isn't included in the metadata import
              file, the resource is deleted when you run the metadata job. Use
              this mode to perform a full sync of the set of entries in the job
              scope.
           INCREMENTAL
              Only the entries and aspects that are explicitly included in the
              metadata import file are modified. Use this mode to modify a
              subset of resources while leaving unreferenced resources
              unchanged.

          This flag argument must be specified if any of the other arguments in
          this group are specified.

       --import-entry-sync-mode=IMPORT_ENTRY_SYNC_MODE
          Type. IMPORT_ENTRY_SYNC_MODE must be one of:

           FULL
              All resources in the job's scope are modified. If a resource
              exists in Dataplex but isn't included in the metadata import
              file, the resource is deleted when you run the metadata job. Use
              this mode to perform a full sync of the set of entries in the job
              scope.
           INCREMENTAL
              Only the entries and aspects that are explicitly included in the
              metadata import file are modified. Use this mode to modify a
              subset of resources while leaving unreferenced resources
              unchanged.

          This flag argument must be specified if any of the other arguments in
          this group are specified.

       --import-source-storage-uri=IMPORT_SOURCE_STORAGE_URI
          The Dataplex source storage URI to import metadata from.

          This flag argument must be specified if any of the other arguments in
          this group are specified.

       --import-log-level=IMPORT_LOG_LEVEL
          Type. IMPORT_LOG_LEVEL must be one of:

           DEBUG
              Debug-level logging. Captures detailed logs for each import item.
              Use debug-level logging to troubleshoot issues with specific
              import items. For example, use debug-level logging to identify
              resources that are missing from the job scope, entries or aspects
              that don't conform to the associated entry type or aspect type,
              or other misconfigurations with the metadata import file..
           INFO
              Info-level logging. Captures logs at the overall job level.
              Includes aggregate logs about import items, but doesn't specify
              which import item has an error..

       --import-source-create-time=IMPORT_SOURCE_CREATE_TIME
          Time at which the event took place. See $ gcloud topic datetimes for
          information on supported time formats.

       A boundary on the scope of impact that the metadata import job can have.

       At least one of these must be specified:

         --import-aspect-types=[IMPORT_ASPECT_TYPES,...]
            The list of aspect types to import metadata jobs into.

         --import-entry-groups=[IMPORT_ENTRY_GROUPS,...]
            The list of entry groups to import metadata jobs into.

         --import-entry-link-types=[IMPORT_ENTRY_LINK_TYPES,...]
            The list of entry link types to import metadata jobs into.

         --import-entry-types=[IMPORT_ENTRY_TYPES,...]
            The list of entry types to import metadata jobs into.

         --import-glossaries=[IMPORT_GLOSSARIES,...]
            The list of glossaries to import metadata jobs into.

         --import-referenced-entry-scopes=[IMPORT_REFERENCED_ENTRY_SCOPES,...]
            The list of referenced entry scopes to import metadata jobs into.

OPTIONAL FLAGS
     --async
        Return immediately, without waiting for the operation in progress to
        complete.

     --labels=[KEY=VALUE,...]
        List of label KEY=VALUE pairs to add.

        Keys must start with a lowercase character and contain only hyphens
        (-), underscores (_), lowercase characters, and numbers. Values must
        contain only hyphens (-), underscores (_), lowercase characters, and
        numbers.

     --validate-only
        Validate the create action, but don't actually perform it.

GCLOUD WIDE FLAGS
    These flags are available to all commands: --access-token-file, --account,
    --billing-project, --configuration, --flags-file, --flatten, --format,
    --help, --impersonate-service-account, --log-http, --project, --quiet,
    --trace-token, --user-output-enabled, --verbosity.

    Run $ gcloud help for details.

NOTES
    This command is currently in alpha and might change without notice. If this
    command fails with API permission errors despite specifying the correct
    project, you might be trying to access an API with an invitation-only early
    access allowlist. This variant is also available:

        $ gcloud dataplex metadata-jobs create

